{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSA algorithms, Part 1: Regex parsing\n",
    "\n",
    "I've been working on a game on and off for a while now, which involves the creation of a DFA or NFA that matches a given regular expression. I worked on something similar as a college project, but the end product was not so great as it was written in OCaml which has middling options for UI (and we spent most of the effort in the project on getting the core functionality working). \n",
    "\n",
    "In this series of posts I hope to go through the implementation of the relevant algorithms for this game in Python, which will make them a lot easier to understand (and also a lot easier to write up as I go). \n",
    "\n",
    "Here's the general plan for the series, which will follow the general algorithms needed for the base game functionality:\n",
    "\n",
    " - Regular expression parsing. This is used for parsing the inputs to levels, so that they can be specified in a typical regex format rather than via some custom format that may be easier to parse but may be more difficult to use in the long run.\n",
    " - Regex to NFA conversion\n",
    " - NFA minimization. The algorithm for converting regular expressions to NFAs can be inefficient, so minimizing the resulting NFA can be a good optimization before proceeding to the DFA conversion.\n",
    " - Efficient NFA to DFA conversion. It's common knowledge that converting an NFA to a DFA can result in exponentially many states, as the DFA has to contain the logic for the superposition of states that an NFA can handle. But there are ways to do this conversion slightly more efficiently than the naive subset method.\n",
    " - DFA minimization. We'll need to minimize DFAs in order to ensure that they are compared accurately. Also, it will help us in scoring the user submission by determining whether fewer states could have been used.\n",
    " - DFA comparison. Once we have the minimized DFAs, we need to compare them. But it's not a simple matter of `dfa1 == dfa2` - the names of the states may differ. We'll use some form of DFS here.\n",
    "\n",
    "This will be a long series, and I hope I can finish it in some reasonable timeframe. For now, here's regex parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex classes\n",
    "\n",
    "First, we need to get some types going. In OCaml, this was pretty easy - the language is made for that kind of stuff. In Python, we'll have to be a bit more mundane and use classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regex:\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "class Union(Regex):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    def __str__(self):\n",
    "        return 'Union({}, {})'.format(str(self.left), str(self.right))\n",
    "\n",
    "\n",
    "class Concat(Regex):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    def __str__(self):\n",
    "        return 'Concat({}, {})'.format(str(self.left), str(self.right))\n",
    "\n",
    "\n",
    "class Star(Regex):\n",
    "    def __init__(self, exp):\n",
    "        self.exp = exp\n",
    "    def __str__(self):\n",
    "        return 'Star({})'.format(str(self.exp))\n",
    "\n",
    "class Letter(Regex):\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    def __str__(self):\n",
    "        return 'Letter({})'.format(self.val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These classes are basically just dummy AST nodes for the actual regular expression operations, along with some pretty printing functionality so we can check our results nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing regex strings algorithmically\n",
    "\n",
    "There are a couple options for parsing the regex strings. One might think of using some kind of parser framework, like PLY or Lark or something similar. But for simple languages like that of regular expressions, this won't be worth the hassle. \n",
    "\n",
    "As you may have noticed by the classes we have, we're not doing anything complicated here as far as regexes go - just the bare minimum (and the usual functionality subset, for courses which cover this materal): Kleene star, concatenation, and union. This subset is small enough that we can just use an algorithm and save ourselves a lot of overhead.\n",
    "\n",
    "Here's a brief summary of the algorithm we're going to use: [Shunting-yard algorithm (Wikipedia)](https://en.m.wikipedia.org/wiki/Shunting_yard_algorithm)\n",
    "\n",
    "This algorithm converts an expression in infix notation into one in postfix notation (RPN, which you may be familiar with from old calculators and programs like `dc`). This stack-based form of notation is much easier for us to parse manually than infix notation.\n",
    "\n",
    "So, our goal here is as follows:\n",
    "\n",
    " - Convert the regular expression string passed into postfix notation\n",
    " - Parse through the stack of this postfix notation and build up a Regex class which will serve as our AST\n",
    "\n",
    "In future sections, we'll parse this AST to get an NFA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shunting-yard implementation\n",
    "\n",
    "First, we need a way to get the precedence of operators. A simple function like this will work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_precedence(op1, op2):\n",
    "    if op1 in ['(', ')']:\n",
    "        return False\n",
    "    if op2 == '*':\n",
    "        return False\n",
    "    if op1 == '*':\n",
    "        return True\n",
    "    if op1 == '+':\n",
    "        return False\n",
    "    if op1 == '&' and op2 == '&':\n",
    "        return False\n",
    "    if op1 == '&' and op2 == '+':\n",
    "        return True\n",
    "    raise SyntaxError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the symbols above, the ampersand (&) may be confusing. This is our proxy for concatenation, since by default concatenation doesn't show up in regular expressions. For instance, the regex `ab` is really $a\\cdot b$, but most of the time we omit the $\\cdot$ as it's just implied. This becomes annoying when we want to actually parse the expressions, so we add these ampersands in like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_concat_ampersands(s):\n",
    "    string_with_concat = '&'.join(list(s))\n",
    "    def remove_bad_concat(char_list):\n",
    "        match char_list:\n",
    "            case []:\n",
    "                return []\n",
    "            case ['*', '&', *rest]:\n",
    "                return ['*'] + remove_bad_concat(rest)\n",
    "            case ['(', '&', *rest]:\n",
    "                return ['('] + remove_bad_concat(rest)\n",
    "            case ['&', ')', *rest]:\n",
    "                return [')'] + remove_bad_concat(rest)\n",
    "            case ['+', '&', *rest]:\n",
    "                return ['+'] + remove_bad_concat(rest)\n",
    "            case ['&', '+', '&', *rest]:\n",
    "                return ['+'] + remove_bad_concat(rest)\n",
    "            case ['&', '+', *rest]:\n",
    "                return ['+'] + remove_bad_concat(rest)\n",
    "            case [head, *rest]:\n",
    "                return [head] + remove_bad_concat(rest)\n",
    "    \n",
    "    return ''.join(remove_bad_concat(list(string_with_concat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we just stick the ampersands everywhere, and then remove the ones that don't have any business being there (like the ones between characters and parentheses, or between other operators and their arguments).\n",
    "\n",
    "You may notice something else a bit strange here, which is that we're removing the ampersands between the stars (or asterisks, or Kleene stars - henceforth referred to as \"stars\") and their arguments in a way that would imply that the stars act on arguments to the *right* of them rather than the usual left. This is due to a limitation of the algorithm we're using to convert to RPN - it's much easier to work with unary operators like unary minus, which appear on the left side of their arguments. We'll get back to this later!\n",
    "\n",
    "For now, let's continue with the RPN-ifying journey. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_of_string_reversed_stars(s):\n",
    "    string_without_bad_concat = add_concat_ampersands(s)\n",
    "\n",
    "    output_queue = []\n",
    "    op_stack = []\n",
    "    \n",
    "    def stack_top(stack):\n",
    "        try:\n",
    "            return stack[-1]\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After correctly adding our concat ampersands, we initialize our queue and stack, which will be used in the algorithm. We also define a quick function to pop from our stack (which may give us `None` if we have issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ...\n",
    "\n",
    "    def parse_token(token):\n",
    "        if token == ' ':\n",
    "            return\n",
    "        if token == '(':\n",
    "            return op_stack.append(token)\n",
    "        if token in ['*', '+', '&']:\n",
    "            while len(op_stack) > 0 and compare_precedence(stack_top(op_stack), token):\n",
    "                output_queue.append(op_stack.pop())\n",
    "            return op_stack.append(token)\n",
    "        if token == ')':\n",
    "            while op_stack[-1] != '(':\n",
    "                output_queue.append(op_stack.pop())\n",
    "            return op_stack.pop()\n",
    "        return output_queue.append(token)\n",
    "\n",
    "    for token in s:\n",
    "        parse_token(token)\n",
    "\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define (and call) another helper function, which parses a given token (character in this case) according to some simple rules:\n",
    "\n",
    " - We ignore any whitespace\n",
    " - We stick any open parens on the stack\n",
    " - If the token is an operator, we use our precedence rules and stack to pop off as many tokens as necessary into our queue\n",
    " - If the token is a close paren, we pop from our stack onto our queue until we see an open paren\n",
    " - If the token is something else (not an operator, paren, or whitespace) we just stick the token directly into the queue\n",
    "\n",
    "For a better explanation on why/how this works, see the above Wikipedia link on the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ...\n",
    "\n",
    "    while len(op_stack) > 0:\n",
    "        output_queue.append(op_stack.pop())\n",
    "\n",
    "    output_stack = []\n",
    "\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare for the second part of the process - converting the RPN into an AST - we put the remaining items on the stack into the queue, and initialize an output stack. (We could have used the same stack as before but `out_stack` is a bit more accurate of a name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ...\n",
    "\n",
    "    def inv_rpn(token):\n",
    "        if token == '&':\n",
    "            a, b = output_stack.pop(), output_stack.pop()\n",
    "            return output_stack.append(Concat(b, a))\n",
    "        if token == '+':\n",
    "            a, b = output_stack.pop(), output_stack.pop()\n",
    "            return output_stack.append(Union(b, a))\n",
    "        if token == '*':\n",
    "            return output_stack.append(Star(output_stack.pop()))\n",
    "        return output_stack.append(Letter(token))\n",
    "\n",
    "    for token in output_queue:\n",
    "        inv_rpn(token)\n",
    "\n",
    "    return output_stack.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define a helper function to parse the RPN into an AST using the classes we created earlier.\n",
    "\n",
    " - If the token is a dyadic operator (two args), we pop two items from the stack and create the relevant object using those items as arguments. (These operators are Concat and Union.)\n",
    " - If the token is a monadic operator (single arg), we pop one item from the stack and create the relevant object using that item as an argument. (Here, the only monadic operator is Star.)\n",
    " - If the token is not an operator, we just append it to the output stack as a Letter (which is basically just putting it there as the character itself).\n",
    "\n",
    "After we define the helper function, we iterate through the RPN'd tokens in the output queue we got from the first part and process each token. When we're done, the only remaining item on the stack should be the final result of the parsing process.\n",
    "\n",
    "Now we just have one task left, which is to reverse the star locations so that we can input the regex with the stars taking arguments on the left instead of on the right as our function requires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reversing the star associativity\n",
    "\n",
    "It turns out that there's not really a super nice way to do this either. We've gotta use another stack and queue, because we're dealing with parentheses.\n",
    "\n",
    "For instance, if we supply `c(a(b*a)*)**` as our regex string, we want to end up with `c*(a*(*ba))` - which might be difficult if we don't account for nested parens correctly.\n",
    "\n",
    "Here's the function, in all its gross glory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_star_locations(s):\n",
    "    stack = []\n",
    "    queue = []\n",
    "    for i in range(len(s)):\n",
    "        if s[i] == '(':\n",
    "            to_stack = '('\n",
    "        elif s[i] == ')':\n",
    "            while stack[-1] != '(':\n",
    "                popped = stack.pop()\n",
    "                queue.insert(0, popped)\n",
    "            stack.pop()\n",
    "            to_stack = '(' + ''.join([str(q) for q in queue]) + ')'\n",
    "            queue = []\n",
    "        elif s[i] == '*':\n",
    "            popped = stack.pop()\n",
    "            to_stack = '*' + popped\n",
    "        else:\n",
    "            to_stack = s[i]\n",
    "        stack.append(to_stack)\n",
    "    return ''.join(stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on here? We initialize our stack and queue, and go to process the items similarly. We're not using a helper function this time, and we're using a temp variable (`to_stack`) to store our action until the end of the loop, so it looks a bit messier.\n",
    "\n",
    " - If the token we see is an open paren, we stick it on the stack\n",
    " - If the token is a close paren, then we pop until we hit an open paren, sticking each of the tokens in the way into the queue. Then, we combine the entire queue into one string with, shove it into the stack, and empty the queue again\n",
    " - If the token is a star, we pop from the stack, put the star in front of what we popped, and shove it back into the stack\n",
    " - Otherwise, we just plop the token on the stack and continue\n",
    "\n",
    "When we're done, we've got a stack with some strings on it. We join them together and return the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're done with all that, we can finally create a single function to give us the AST from a nice regex string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_of_string(s):\n",
    "    stars_reversed = reverse_star_locations(s)\n",
    "    output = regex_of_string_reversed_stars(stars_reversed)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope you enjoyed! If you liked this check out the other stuff on my website. See you next time!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
